{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SS_lab1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2MN/NHoWvA+iM6PntxMfB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lenaami/SpeechSynthesisLabs/blob/main/SS_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE_O2ye2NxIG",
        "outputId": "72090247-a4e7-41e3-a09d-c6aae46c811a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjbICZ1UNxFf"
      },
      "source": [
        "path = '/content/gdrive/My Drive/Colab Notebooks/Синтез речи/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3t3WxJKWWoF"
      },
      "source": [
        "book1 = 'r_hod.Result.xml'\n",
        "book2 = 'tropa.Result.xml'\n",
        "book3 = 'whtguard.Result.xml'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKVWcZSzjQr1"
      },
      "source": [
        "# Парсинг xml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoBO8OkFNxDE"
      },
      "source": [
        "import xml.etree.ElementTree as ET \n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDZaYA1z6ws_"
      },
      "source": [
        "def isNone(a):\n",
        "    return int(a) if a is not None else -1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ04tRJYVE_M"
      },
      "source": [
        "# n-граммы\n",
        "def add_n_gramm(n_gramm, X):\n",
        "    zero_word = (-1) * np.ones(X.shape[1], dtype = int)\n",
        "\n",
        "    X_gram = X.copy()\n",
        "\n",
        "    for i in range(n_gramm):\n",
        "        X_gram = np.vstack((zero_word, X_gram, zero_word))\n",
        "\n",
        "    for i in range(1, n_gramm + 1):\n",
        "        X = np.hstack((X_gram[(n_gramm - i):-(n_gramm + i), :], X, X_gram[(i + n_gramm):(X_gram.shape[0] - n_gramm + i), :]))\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgB56mEgf1Hw"
      },
      "source": [
        "def get_data(file, n_gramm = 0, bySentence = False):\n",
        "    X = []\n",
        "    y = []\n",
        "    words = []\n",
        "\n",
        "    tree = ET.parse(file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    for snt in root.findall('sentence'):\n",
        "        features = []\n",
        "        words_snt = []   \n",
        "        for wrd in snt.findall('word'): # теги слова       \n",
        "            words_snt.append(wrd.get('original'))\n",
        "\n",
        "            feat_wrd = []\n",
        "            dct = wrd.find('dictitem')\n",
        "            feat_wrd.append(isNone(dct.get('form'))) \n",
        "            feat_wrd.append(isNone(dct.get('subpart_of_speech')))     \n",
        "            feat_wrd.append(isNone(dct.get('semantics1')))\n",
        "            feat_wrd.append(isNone(dct.get('semantics2')))        \n",
        "            feat_wrd.append(isNone(wrd.find('letter').get('flag')))\n",
        "\n",
        "            features.append(feat_wrd)\n",
        "        for i, cnt in enumerate(snt.findall('content')): # пунктуация и эмфазы\n",
        "            features[i].append(isNone(cnt.get('PunktBeg')))\n",
        "            features[i].append(isNone(cnt.get('PunktEnd')))\n",
        "            features[i].append(isNone(cnt.get('EmphBeg')))\n",
        "            features[i].append(isNone(cnt.get('EmphEnd')))   \n",
        "    \n",
        "        # чистка от None \n",
        "        for i in range(len(words_snt) - 1, -1, -1):\n",
        "            if words_snt[i] is None:\n",
        "                words_snt.pop(i)\n",
        "                features.pop(i)\n",
        "\n",
        "        y_snt = np.zeros(len(words_snt), dtype = int)\n",
        "        y_snt[-1] = 1\n",
        "\n",
        "        # объединение предложений в один массив\n",
        "        if bySentence:\n",
        "            X.append(features)\n",
        "            y.append(y_snt)\n",
        "            words.append(words_snt)\n",
        "        else:\n",
        "            X.extend(features)            \n",
        "            y.extend(y_snt)           \n",
        "            words.extend(words_snt)\n",
        "\n",
        "    if bySentence == False:\n",
        "        y = np.asarray(y)\n",
        "        X = np.asarray(X)\n",
        "        X = add_n_gramm(n_gramm, X)\n",
        "    \n",
        "    return X, y, words"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvRXn9cAmDPr"
      },
      "source": [
        "X_train_1, y_train_1, words_1 = get_data(path + book2, n_gramm=2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NintYyjTvlI5"
      },
      "source": [
        "X_train_2, y_train_2, words_2 = get_data(path + book3, n_gramm=2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcJHqdL0vv_v"
      },
      "source": [
        "# Объединение корпусов (2 и 3)\n",
        "\n",
        "X_train = np.vstack((X_train_1, X_train_2))\n",
        "y_train = np.vstack((y_train_1.reshape(-1, 1), y_train_2.reshape(-1, 1))).reshape(-1, )"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq_lFG8psmCP"
      },
      "source": [
        "# Тестовый корпус (1)\n",
        "\n",
        "X_test, y_test, words = get_data(path + book1, n_gramm=2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9dEwvsJjWUt"
      },
      "source": [
        "# Сложные предложения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y10U5HI5FOa9"
      },
      "source": [
        "def get_sentence(num, X_snt, y_snt, words_snt):\n",
        "    X = [ft for ft in X_snt[num]]\n",
        "    y = [y for y in y_snt[num]]\n",
        "    words = [wrd for wrd in words_snt[num]]\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y) \n",
        "    return X, y, words"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0cNPDP3EB_u"
      },
      "source": [
        "def add_n_gramm_diff(num, n_gramm, X_snt, y_snt, words_snt):\n",
        "    X = []\n",
        "    y = []\n",
        "    words = []\n",
        "    len = []\n",
        "    for i in range(-1, 2):\n",
        "        X_s, y_s, w_s = get_sentence(num + i, X_snt, y_snt, words_snt)\n",
        "        X.extend(X_s)\n",
        "        y.extend(y_s)\n",
        "        words.extend(w_s)\n",
        "        len.append(X_s.shape[0])\n",
        "\n",
        "    X = np.asarray(X)    \n",
        "    X = add_n_gramm(n_gramm, X)\n",
        "    X = X[len[0]:(len[0] + len[1])]\n",
        "    y = y[len[0]:(len[0] + len[1])]\n",
        "    words =  words[len[0]:(len[0] + len[1])]    \n",
        "\n",
        "    return X, y, words"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O0Ko9gEqcmn"
      },
      "source": [
        "# Корпуса, где признаки слов разделены по преложениям\n",
        "\n",
        "X_snt_1, y_snt_1, words_snt_1 = get_data(path + book1, bySentence=True)\n",
        "X_snt_3, y_snt_3, words_snt_3 = get_data(path + book3, bySentence=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6z57xuSqu7C"
      },
      "source": [
        "# Сложное предложение\n",
        "\n",
        "X_diff, y_diff, words_diff = add_n_gramm_diff(47, 2, X_snt_1, y_snt_1, words_snt_1)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlOz09z1hUdI"
      },
      "source": [
        "# Сложные предложения\n",
        "# book1: 14, 47; book3: 4209\n",
        "\n",
        "y_diff = []\n",
        "words_diff = []\n",
        "\n",
        "X_diff_1, y_diff_1, words_diff_1 = add_n_gramm_diff(14, 2, X_snt_1, y_snt_1, words_snt_1)\n",
        "y_diff.extend(y_diff_1)\n",
        "words_diff.extend(words_diff_1)\n",
        "\n",
        "X_diff_2, y_diff_2, words_diff_2 = add_n_gramm_diff(47, 2, X_snt_1, y_snt_1, words_snt_1)\n",
        "X_diff = np.vstack((X_diff_1, X_diff_2))\n",
        "y_diff.extend(y_diff_2)\n",
        "words_diff.extend(words_diff_2)\n",
        "\n",
        "X_diff_3, y_diff_3, words_diff_3 = add_n_gramm_diff(4208, 2, X_snt_3, y_snt_3, words_snt_3)\n",
        "X_diff = np.vstack((X_diff, X_diff_3))\n",
        "y_diff.extend(y_diff_3)\n",
        "words_diff.extend(words_diff_3)\n",
        "\n",
        "X_diff_4, y_diff_4, words_diff_4 = add_n_gramm_diff(4209, 2, X_snt_3, y_snt_3, words_snt_3)\n",
        "X_diff = np.vstack((X_diff, X_diff_4))\n",
        "y_diff.extend(y_diff_4)\n",
        "words_diff.extend(words_diff_4)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QjvyalUJNwr",
        "outputId": "62827b80-d2c2-4775-87a4-851317f58f94"
      },
      "source": [
        "_, ys, ws = get_sentence(47, X_snt_1, y_snt_1, words_snt_1)\n",
        "print(ws)\n",
        "print(ys)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Еще', 'не', 'хватает', 'здесь', 'пивного', 'ларька,', 'чтоб', 'эти', 'чубатые', 'вытянувшиеся', 'ребята -', 'порода', 'наша', 'не', 'мельчает! -', 'сдували', 'бы', 'белую', 'пену', 'на', 'могилы.']\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFGG9qD06YN8",
        "outputId": "ef275d0b-2006-4c2c-8345-4a8730acf63e"
      },
      "source": [
        "_, ys, ws = get_sentence(4209, X_snt_3, y_snt_3, words_snt_3)\n",
        "print(ws)\n",
        "print(ys)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['14-го', 'дек.', '1918', 'г.', '4', 'ч.', 'дня\".']\n",
            "[0 0 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGcOvwg6isBe"
      },
      "source": [
        "#Классификаторы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BANG5glggz5w"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLqcXG-7njFq"
      },
      "source": [
        "def fit_clf(clf, X_train, y_train):\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "def predict_clf(clf, X_test, y_test, result = False):\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    print('F1-score (binary):\\t%0.3f' % metrics.f1_score(y_test, y_pred, average='binary'))\n",
        "    print('Recall (binary): \\t%0.3f' % metrics.recall_score(y_test, y_pred, average='binary'))\n",
        "    print('Precision (binary):\\t%0.3f' % metrics.precision_score(y_test, y_pred, average='binary'))\n",
        "    print('Accuracy:\\t\\t%0.3f' % metrics.accuracy_score(y_test, y_pred))\n",
        "    \n",
        "    print('\\nConfusion matrix:\\n', pd.DataFrame(metrics.confusion_matrix(y_test, y_pred), index=['0', '1'], columns=['0', '1']))\n",
        "    #metrics.plot_confusion_matrix(clf, X_test, y_test, values_format='d')\n",
        "    #plt.show()\n",
        "\n",
        "    if result:\n",
        "        return y_pred\n",
        "\n",
        "def cross_val_clf(clf, X, y):\n",
        "    scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=5, scoring='f1')\n",
        "    df_scores = pd.DataFrame({'Srocc Val Scores (F1)': scores}, index=['1', '2', '3', '4', '5'])\n",
        "    print(df_scores)\n",
        "    print('Average:\\t%0.3f\\n' % np.mean(scores))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gjp3j_fBqqF"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlHx1Vm1i6NL"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-zop2EGHPTP",
        "outputId": "76a0873f-b4cb-4f9d-8f35-bb27d9f4a1c1"
      },
      "source": [
        "tree = DecisionTreeClassifier()\n",
        "    \n",
        "cross_val_clf(tree, X_train, y_train)\n",
        "\n",
        "tree = fit_clf(tree, X_train, y_train)\n",
        "predict_clf(tree, X_test, y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Srocc Val Scores (F1)\n",
            "1               0.993944\n",
            "2               0.992922\n",
            "3               0.995203\n",
            "4               0.980978\n",
            "5               0.982854\n",
            "Average:\t0.989\n",
            "\n",
            "F1-score (binary):\t0.984\n",
            "Recall (binary): \t0.989\n",
            "Precision (binary):\t0.979\n",
            "Accuracy:\t\t0.998\n",
            "\n",
            "Confusion matrix:\n",
            "       0   1\n",
            "0  1160   2\n",
            "1     1  93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv04biRv7Hh2",
        "outputId": "06d40630-bcbc-4132-9cdb-fc773659f34f"
      },
      "source": [
        "predict_clf(tree, X_diff, y_diff, result=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score (binary):\t1.000\n",
            "Recall (binary): \t1.000\n",
            "Precision (binary):\t1.000\n",
            "Accuracy:\t\t1.000\n",
            "\n",
            "Confusion matrix:\n",
            "      0  1\n",
            "0  105  0\n",
            "1    0  4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beaCtn5Wi8K-"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xisO3HDg5LPQ",
        "outputId": "94a67f5f-702f-4e64-8f5a-1819ed51abfa"
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=10)\n",
        "\n",
        "cross_val_clf(rf, X_train, y_train)\n",
        "\n",
        "rf = fit_clf(rf, X_train, y_train)\n",
        "predict_clf(rf, X_test, y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Srocc Val Scores (F1)\n",
            "1               0.988701\n",
            "2               0.986694\n",
            "3               0.989498\n",
            "4               0.974242\n",
            "5               0.972850\n",
            "Average:\t0.982\n",
            "\n",
            "F1-score (binary):\t0.967\n",
            "Recall (binary): \t0.947\n",
            "Precision (binary):\t0.989\n",
            "Accuracy:\t\t0.995\n",
            "\n",
            "Confusion matrix:\n",
            "       0   1\n",
            "0  1161   1\n",
            "1     5  89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_urwC5AEN0YJ",
        "outputId": "81df810a-e71f-4d33-cc4c-b9c3fe1b3f63"
      },
      "source": [
        "predict_clf(rf, X_diff, y_diff, result=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score (binary):\t1.000\n",
            "Recall (binary): \t1.000\n",
            "Precision (binary):\t1.000\n",
            "Accuracy:\t\t1.000\n",
            "\n",
            "Confusion matrix:\n",
            "      0  1\n",
            "0  105  0\n",
            "1    0  4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaLLlmsei-it"
      },
      "source": [
        "## Naive Baies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GooiZGmeFPAG",
        "outputId": "0166401e-2f92-4b1d-d4b7-4af7d52a34f4"
      },
      "source": [
        "nb = GaussianNB(var_smoothing=1e-5)\n",
        "\n",
        "cross_val_clf(nb, X_train, y_train)\n",
        "\n",
        "nb = fit_clf(nb, X_train, y_train)\n",
        "predict_clf(nb, X_test, y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Srocc Val Scores (F1)\n",
            "1               0.800386\n",
            "2               0.784450\n",
            "3               0.815916\n",
            "4               0.757515\n",
            "5               0.751063\n",
            "Average:\t0.782\n",
            "\n",
            "F1-score (binary):\t0.780\n",
            "Recall (binary): \t0.851\n",
            "Precision (binary):\t0.721\n",
            "Accuracy:\t\t0.964\n",
            "\n",
            "Confusion matrix:\n",
            "       0   1\n",
            "0  1131  31\n",
            "1    14  80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx5P0m3WRyMt",
        "outputId": "f4b0fcad-1c22-430e-a216-1f97ef5fb458"
      },
      "source": [
        "predict_clf(nb, X_diff, y_diff, result=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score (binary):\t0.462\n",
            "Recall (binary): \t0.750\n",
            "Precision (binary):\t0.333\n",
            "Accuracy:\t\t0.936\n",
            "\n",
            "Confusion matrix:\n",
            "     0  1\n",
            "0  99  6\n",
            "1   1  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwT6TDJ2jDbq"
      },
      "source": [
        "## Logisric Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpPP6aqEPZSK",
        "outputId": "1857d454-fad5-4e3d-e9ff-f1ec32717e1a"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "\n",
        "cross_val_clf(lr, X_train, y_train)\n",
        "\n",
        "lr = fit_clf(lr, X_train, y_train)\n",
        "predict_clf(lr, X_test, y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Srocc Val Scores (F1)\n",
            "1               0.881639\n",
            "2               0.872214\n",
            "3               0.877551\n",
            "4               0.812631\n",
            "5               0.824354\n",
            "Average:\t0.854\n",
            "\n",
            "F1-score (binary):\t0.896\n",
            "Recall (binary): \t0.872\n",
            "Precision (binary):\t0.921\n",
            "Accuracy:\t\t0.985\n",
            "\n",
            "Confusion matrix:\n",
            "       0   1\n",
            "0  1155   7\n",
            "1    12  82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQiXxGUqR01v",
        "outputId": "b382f00c-fbe3-457d-9f46-b12a72876933"
      },
      "source": [
        "predict_clf(lr, X_diff, y_diff, result=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score (binary):\t0.750\n",
            "Recall (binary): \t0.750\n",
            "Precision (binary):\t0.750\n",
            "Accuracy:\t\t0.982\n",
            "\n",
            "Confusion matrix:\n",
            "      0  1\n",
            "0  104  1\n",
            "1    1  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtfq_5d7jHD9"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idjSWaswPbex",
        "outputId": "f15b2f0e-6ac5-452a-b877-4925c26b79d9"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "cross_val_clf(knn, X_train, y_train)\n",
        "\n",
        "knn = fit_clf(knn, X_train, y_train)\n",
        "predict_clf(knn, X_test, y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Srocc Val Scores (F1)\n",
            "1               0.733127\n",
            "2               0.724360\n",
            "3               0.734315\n",
            "4               0.615432\n",
            "5               0.639537\n",
            "Average:\t0.689\n",
            "\n",
            "F1-score (binary):\t0.658\n",
            "Recall (binary): \t0.564\n",
            "Precision (binary):\t0.791\n",
            "Accuracy:\t\t0.956\n",
            "\n",
            "Confusion matrix:\n",
            "       0   1\n",
            "0  1148  14\n",
            "1    41  53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2vhiXL6R1KV",
        "outputId": "90c976d7-6088-41dd-d57c-b1cc5763c3e1"
      },
      "source": [
        "predict_clf(knn, X_diff, y_diff, result=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score (binary):\t0.571\n",
            "Recall (binary): \t0.500\n",
            "Precision (binary):\t0.667\n",
            "Accuracy:\t\t0.972\n",
            "\n",
            "Confusion matrix:\n",
            "      0  1\n",
            "0  104  1\n",
            "1    2  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}